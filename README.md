# Proyecto Final de Machine Learning - Database II
## An√°lisis de Clasificaci√≥n del Dataset Yeast

Este proyecto implementa un an√°lisis completo de **clasificaci√≥n multiclase** sobre el dataset Yeast (Protein Localization Sites), aplicando t√©cnicas avanzadas de manejo de desbalanceo, selecci√≥n de caracter√≠sticas y optimizaci√≥n de modelos.

## üìÅ Estructura del Proyecto

```
ML_ProyectoFinalDB2/
‚îú‚îÄ‚îÄ DATABASE/
‚îÇ   ‚îú‚îÄ‚îÄ yeast.data          # Dataset principal
‚îÇ   ‚îî‚îÄ‚îÄ yeast.names         # Descripci√≥n del dataset
‚îú‚îÄ‚îÄ yeast_ml_analysis.ipynb # Notebook principal con todo el an√°lisis
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md              # Este archivo
```

## üìä Dataset

**Yeast Protein Localization Sites**
- **Instancias**: 1,484
- **Caracter√≠sticas**: 8 num√©ricas + 1 nombre
- **Clases**: 10 (sitios de localizaci√≥n de prote√≠nas)
- **Fuente**: UCI Machine Learning Repository

### Caracter√≠sticas del Dataset:
1. `mcg`: McGeoch's method for signal sequence recognition
2. `gvh`: von Heijne's method for signal sequence recognition  
3. `alm`: Score of ALOM membrane spanning region prediction
4. `mit`: Discriminant analysis of mitochondrial proteins
5. `erl`: Presence of "HDEL" substring
6. `pox`: Peroxisomal targeting signal
7. `vac`: Discriminant analysis of vacuolar proteins
8. `nuc`: Discriminant analysis of nuclear proteins

### Clases:
- CYT (cytosolic/cytoskeletal): 463
- NUC (nuclear): 429
- MIT (mitochondrial): 244
- ME3 (membrane protein, no signal): 163
- ME2 (membrane protein, uncleaved): 51
- ME1 (membrane protein, cleaved): 44
- EXC (extracellular): 37
- VAC (vacuolar): 30
- POX (peroxisomal): 20
- ERL (endoplasmic reticulum): 5

## üõ†Ô∏è M√©todos Implementados

### 1. Carga de Datos
- **Fuente Oficial**: UCI ML Repository mediante `ucimlrepo` (ID: 110)
- **Sin valores faltantes**: Dataset confirmado completo
- **An√°lisis de desbalanceo**: Identificaci√≥n de clases minoritarias

### 2. Evaluaci√≥n de Escalamiento
- Comparaci√≥n de rendimiento con/sin escalamiento
- **StandardScaler**: Para modelos sensibles a la escala

### 3. Detecci√≥n de Outliers (PyOD) con Protecci√≥n de Clases Minoritarias
- **KNN**: K-Nearest Neighbors para detecci√≥n de anomal√≠as
- **Isolation Forest**: Aislamiento aleatorio de observaciones
- **LOF**: Local Outlier Factor
- **CR√çTICO**: Protecci√≥n de outliers en clases minoritarias (< 5%)

### 4. Selecci√≥n de Caracter√≠sticas
- **RFE (Recursive Feature Elimination)**: Con RandomForestClassifier
- **Lasso (L1)**: Logistic Regression con regularizaci√≥n L1
- **Stepwise (Forward Selection)**: B√∫squeda secuencial hacia adelante

### 5. Manejo de Desbalanceo
- **SMOTE**: Synthetic Minority Over-sampling Technique
- **Random Oversampling**: Sobremuestreo aleatorio
- Mejora de Balanced Accuracy

### 6. Modelos de Clasificaci√≥n con Regularizaci√≥n
- **Ridge (L2)**: Logistic Regression con penalizaci√≥n L2
- **Lasso (L1)**: Logistic Regression con penalizaci√≥n L1
- **Elastic Net**: Logistic Regression con L1 + L2
- **GridSearchCV**: Optimizaci√≥n de hiperpar√°metros

### 7. Modelos Ensemble y Avanzados
- **√Årbol de Decisi√≥n**: Clasificador optimizado
- **Random Forest**: Ensemble de √°rboles
- **Gradient Boosting**: Boosting secuencial
- **SVM**: Support Vector Machine con kernel RBF

### 8. M√©tricas de Clasificaci√≥n
- **Accuracy**: Tasa de acierto global
- **Balanced Accuracy**: Ajustada por desbalanceo
- **F1-Score (weighted)**: Balance precision/recall ponderado
- **Classification Report**: M√©tricas por clase

## üì¶ Instalaci√≥n

### Requisitos Previos
- Python 3.8 o superior
- pip

### Pasos de Instalaci√≥n

1. Clonar o descargar el repositorio

2. Instalar las dependencias:
```bash
pip install -r requirements.txt
```

### Dependencias Principales
```
pandas==2.0.3
numpy==1.24.3
scikit-learn==1.3.0
matplotlib==3.7.2
seaborn==0.12.2
pyod==1.1.0
mlxtend==0.22.0
jupyter==1.0.0
imbalanced-learn==0.11.0
ucimlrepo
```

## üöÄ Uso

### Ejecutar el An√°lisis Completo

1. Abrir Jupyter Notebook:
```bash
jupyter notebook yeast_ml_analysis.ipynb
```

2. Ejecutar todas las celdas secuencialmente (Cell ‚Üí Run All)

### Estructura del Notebook

El notebook est√° organizado en las siguientes secciones:

1. **Importar Librer√≠as**: Carga de todas las dependencias necesarias
2. **Carga y Exploraci√≥n de Datos**: Desde UCI ML Repository oficial
3. **Preparaci√≥n de Datos**: An√°lisis de desbalanceo y codificaci√≥n
4. **Evaluaci√≥n de Escalamiento**: Comparaci√≥n con/sin scaling
5. **Detecci√≥n de Outliers**: PyOD con protecci√≥n de clases minoritarias
6. **Selecci√≥n de Caracter√≠sticas**: RFE, Lasso, Stepwise
7. **Manejo de Desbalanceo**: SMOTE y Random Oversampling
8. **Modelos de Clasificaci√≥n**: Regularizaci√≥n y optimizaci√≥n
9. **√Årboles de Decisi√≥n y Ensemble**: RF, GB, SVM
10. **Comparativa Final**: Evaluaci√≥n con m√©tricas de clasificaci√≥n
11. **Conclusiones**: Resumen y recomendaciones

## üìà Resultados Esperados

El notebook genera:

- **Visualizaciones**:
  - Distribuci√≥n de clases y desbalanceo
  - Matriz de correlaci√≥n
  - An√°lisis de outliers por clase
  - Comparaci√≥n de m√©todos de selecci√≥n de caracter√≠sticas
  - √Årboles de decisi√≥n visualizados
  - Matriz de confusi√≥n
  - Gr√°ficas comparativas de modelos

- **M√©tricas de Clasificaci√≥n**:
  - **Accuracy**: Tasa de acierto
  - **Balanced Accuracy**: Ajustada por desbalanceo
  - **F1-Score (weighted)**: Balance precision/recall
  - **Classification Report**: Precision, Recall, F1 por clase
  - Importancia de caracter√≠sticas

- **Comparativa Final**:
  - Tabla resumen con todos los modelos
  - Recomendaciones sobre qu√© modelo usar

## üìù An√°lisis Realizados

### Preprocesamiento
- Introducci√≥n artificial de valores faltantes (5%)
- Comparaci√≥n de t√©cnicas de imputaci√≥n
- Detecci√≥n y remoci√≥n de outliers por consenso

### Feature Engineering
- Selecci√≥n mediante 3 m√©todos diferentes
- Identificaci√≥n de caracter√≠sticas m√°s relevantes
- An√°lisis de importancia

### Modelado
- Optimizaci√≥n de hiperpar√°metros con GridSearch
- Validaci√≥n cruzada de 5 folds
- Comparaci√≥n exhaustiva de modelos

## üéØ Conclusiones Principales

1. **Imputaci√≥n**: KNNImputer demostr√≥ ser m√°s robusto que Forward/Backward Fill
2. **Outliers**: El consenso de m√∫ltiples m√©todos mejora la calidad del dataset
3. **Selecci√≥n de Features**: Los 3 m√©todos identificaron caracter√≠sticas comunes relevantes
4. **Regularizaci√≥n**: Elastic Net ofrece un buen balance entre Ridge y Lasso
5. **√Årboles**: La optimizaci√≥n de hiperpar√°metros mejora significativamente el desempe√±o

## üë• Autores

Proyecto Final - Base de Datos II  
Universidad de Lima - Ciclo VIII  
Machine Learning

## üìÑ Licencia

Este proyecto es parte de un trabajo acad√©mico.

## üîó Referencias

- Dataset: [UCI Machine Learning Repository - Yeast](https://archive.ics.uci.edu/ml/datasets/Yeast)
- Nakai, K., & Kanehisa, M. (1991). Expert system for predicting protein localization sites in gram-negative bacteria
- Horton, P., & Nakai, K. (1996). A probabilistic classification system for predicting the cellular localization sites of proteins

## üìß Contacto

Para preguntas o sugerencias sobre este proyecto, contactar al equipo de desarrollo.

---

**Nota**: Este es un proyecto acad√©mico que demuestra la aplicaci√≥n pr√°ctica de t√©cnicas de Machine Learning vistas en el curso.
